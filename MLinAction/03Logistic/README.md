Logistic回归
============

一、理论简介
----------
Logistic回归，也就是常说的逻辑回归，但要注意的是，这其实是一个分类问题。可能大多数用逻辑回归是用来做二分类，但其实多元分类问题也同样是适用的。详细理论推导我这里不打算展开，因为网上真的有太多关于这方面的教程。
下面我给一下 吴恩达逻辑回归文字版的链接仅供参考：[Logistic回归](http://www.ai-start.com/ml2014/html/week3.html)

二、案例背景
-----------
使用 Logistic 回归来预测患有疝病的马的存活问题。疝病是描述马胃肠痛的术语。然而，这种病不一定源自马的胃肠问题，其他问题也可能引发马疝病。这个数据集中包含了医院检测马疝病的一些指标，有的指标比较主观，有的指标难以测量，例如马的疼痛级别。

三、缺失数据
-----------
本次实验初次涉及到如何处理残缺数据的情况。针对本次实验，我们采用如下方式：
- 所有的缺失值必须用一个实数值来替换，因为我们使用的 NumPy 数据类型不允许包含缺失值。我们这里选择实数 0 来替换所有缺失值，恰好能适用于 Logistic 回归。这样做的直觉在于，我们需要的是一个在更新时不会影响系数的值。回归系数的更新公式如下:
weights = weights + alpha * error * dataMatrix[dataIndex[randIndex]]。如果 dataMatrix 的某个特征对应值为 0，那么该特征的系数将不做更新，即:weights = weights
另外，由于 Sigmoid(0) = 0.5 ，即它对结果的预测不具有任何倾向性，因此我们上述做法也不会对误差造成任何影响。基于上述原因，将缺失值用 0 代替既可以保留现有数据，也不需要对优化算法进行修改。此外，该数据集中的特征取值一般不为 0，因此在某种意义上说它也满足 “特殊值” 这个要求。
- 如果在测试数据集中发现了一条数据的类别标签已经缺失，那么我们的简单做法是将该条数据丢弃。这是因为类别标签与特征不同，很难确定采用某个合适的值来替换。采用 Logistic 回归进行分类时这种做法是合理的，而如果采用类似 kNN 的方法，则保留该条数据显得更加合理。

四、核心算法
-----------
本次实验的核心算法是“随机梯度上升”法。为什么是“上升”而不是常听到的“下降”呢？<br>
这里的假设函数(h)是经过sigmoid函数变换得到的，其实际意义是在参数为w的时候，取x的情况下y=1的概率。所以这是一个概率问题，我们通过“极大似然估计”的方法，最终得到了似然函数，通过随机梯度上升算法，可以似然函数取得最大值的时候，参数w向量的值。采用“上升”还是“下降”仅仅取决于我们需要找的是“最大值”还是“最小值”。本题也可以转化为“求损失函数的最小值”，这样就是用“梯度下降”算法了。
